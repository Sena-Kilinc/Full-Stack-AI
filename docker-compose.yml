services:
  ml-pipeline-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ml-pipeline-api
    ports:
      - "8000:8000"
    volumes:
      # Data, models ve logs için persistent volumes
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
      - ./eda_outputs:/app/eda_outputs
      - ./comparison_outputs:/app/comparison_outputs
      # Development için source code mounting - tüm dosyalar için
      - .:/app
    environment:
      # Application settings
      - APP_NAME=ML Pipeline API
      - APP_VERSION=1.0.0
      - DEBUG=false
      
      # Server settings
      - HOST=0.0.0.0
      - PORT=8000
      - WORKERS=1
      
      # Directories
      - DATA_DIR=/app/data
      - MODELS_DIR=/app/models
      - LOGS_DIR=/app/logs
      - EDA_OUTPUTS_DIR=/app/eda_outputs
      - COMPARISON_OUTPUTS_DIR=/app/comparison_outputs
      
      # Logging
      - LOG_LEVEL=INFO
      - LOG_FILE=app.log
      
      # ML Settings
      - DEFAULT_TEST_SIZE=0.25
      - DEFAULT_RANDOM_STATE=42
      - DEFAULT_ALGORITHM=random_forest
      - USE_FIXED_SPLIT=true
      - FIXED_TRAIN_SIZE=150
      - FIXED_TEST_SIZE=50
      
      # Performance
      - PYTHONUNBUFFERED=1
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

networks:
  ml-network:
    driver: bridge